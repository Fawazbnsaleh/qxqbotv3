#!/usr/bin/env python3
"""
COMPREHENSIVE FIX: All Remaining Issues
- Remove duplicates
- Fix short samples 
- Fix hidden services in Normal
- Fix cross-category leaks
- Fix questions in violations
"""
import json
from collections import Counter

print('üõ†Ô∏è COMPREHENSIVE FIX: All Remaining Issues')
print('=' * 70)

file_path = 'al_rased/data/labeledSamples/training_data.json'
with open(file_path, 'r') as f:
    data = json.load(f)

original_count = len(data)
fixes = {
    'duplicates_removed': 0,
    'short_removed': 0,
    'hidden_services_fixed': 0,
    'cross_category_fixed': 0,
    'questions_fixed': 0,
}

# ========== 1. REMOVE DUPLICATES ==========
print('\nüîÅ 1. Removing Duplicates...')
seen_texts = set()
unique_data = []
for d in data:
    txt = d.get('text', '')
    if txt not in seen_texts:
        seen_texts.add(txt)
        unique_data.append(d)
    else:
        fixes['duplicates_removed'] += 1
data = unique_data
print(f'   Removed: {fixes["duplicates_removed"]}')

# ========== 2. FIX SHORT SAMPLES ==========
print('\nüìè 2. Fixing Short Samples (< 15 chars)...')
# Keep short samples ONLY if they have strong keywords
strong_keywords = ['ÿ≥ŸÉÿ≥', 'ÿ≥ŸÉŸÑŸäŸÅ', 'ÿ™ŸáŸÉŸäÿ±', 'ÿ≠ÿ¥Ÿäÿ¥', 'ÿßÿÆÿ™ÿ±ÿßŸÇ']
filtered_data = []
for d in data:
    txt = d.get('text', '')
    if len(txt) < 15:
        has_strong = any(k in txt.lower() for k in strong_keywords)
        if not has_strong:
            fixes['short_removed'] += 1
            continue  # Remove
    filtered_data.append(d)
data = filtered_data
print(f'   Removed: {fixes["short_removed"]}')

# ========== 3. FIX HIDDEN SERVICES IN NORMAL ==========
print('\nüü¢ 3. Fixing Hidden Services in Normal...')
service_patterns = {
    'Academic Cheating': ['ÿ≠ŸÑ Ÿàÿßÿ¨ÿ®ÿßÿ™', 'ŸÜÿ≠ŸÑ Ÿàÿßÿ¨ÿ®ÿßÿ™', 'ÿ≠ŸÑ ŸÖÿ¥ÿßÿ±Ÿäÿπ', 'ŸÉÿ™ÿßÿ®ÿ© ÿ®ÿ≠Ÿàÿ´', 'ÿ≠ŸÑ ÿßÿÆÿ™ÿ®ÿßÿ±ÿßÿ™'],
    'Medical Fraud': ['ÿ≥ŸÉŸÑŸäŸÅ', 'ÿßÿ¨ÿßÿ≤ÿ© ŸÖÿ±ÿ∂Ÿäÿ©', 'ÿßÿ¨ÿßÿ≤ÿßÿ™ ŸÖÿ±ÿ∂Ÿäÿ©', 'ÿπÿ∞ÿ± ÿ∑ÿ®Ÿä'],
    'Financial Scams': ['ÿßÿ≥ÿ™ÿ´ŸÖÿ± ŸÖÿπŸä', 'ÿßÿ±ÿ®ÿßÿ≠ ŸäŸàŸÖŸäÿ©', 'ÿßÿ±ÿ®ÿßÿ≠ ŸÖÿ∂ŸÖŸàŸÜÿ©', 'ŸÅÿ±ÿµÿ© ÿßÿ≥ÿ™ÿ´ŸÖÿßÿ±Ÿäÿ©'],
}
student_keywords = ['ÿßÿ®Ÿä', 'ÿßÿ®ÿ∫Ÿâ', 'ŸÖŸäŸÜ', 'ŸÖŸÖŸÉŸÜ', 'ÿßÿ≠ÿ™ÿßÿ¨', 'ŸàŸäŸÜ', 'ŸÉŸäŸÅ']

for d in data:
    if d.get('label') != 'Normal':
        continue
    
    txt = d.get('text', '').lower()
    
    # Check if it's a student asking (NOT a service)
    is_student = any(k in txt for k in student_keywords)
    
    for category, patterns in service_patterns.items():
        if any(p in txt for p in patterns):
            # Only fix if NOT a student question
            if not is_student or 'ŸÑŸÑÿ™ŸàÿßÿµŸÑ' in txt or 'ŸÖÿ™ŸàŸÅÿ±' in txt:
                d['label'] = category
                d['fixed_by'] = 'comprehensive_fix_hidden_service'
                fixes['hidden_services_fixed'] += 1
                break

print(f'   Fixed: {fixes["hidden_services_fixed"]}')

# ========== 4. FIX CROSS-CATEGORY LEAKS ==========
print('\nüè• 4. Fixing Cross-Category Leaks...')

for d in data:
    txt = d.get('text', '').lower()
    label = d.get('label', '')
    
    # Medical Fraud with pure Academic content -> Academic Cheating
    if label == 'Medical Fraud':
        has_academic = any(k in txt for k in ['Ÿàÿßÿ¨ÿ®', 'ÿ®ÿ≠ÿ´', 'ŸÖÿ¥ÿ±Ÿàÿπ ÿ™ÿÆÿ±ÿ¨', 'ÿ±ÿ≥ÿßŸÑÿ© ŸÖÿßÿ¨ÿ≥ÿ™Ÿäÿ±'])
        has_medical = any(k in txt for k in ['ÿ≥ŸÉŸÑŸäŸÅ', 'ÿßÿ¨ÿßÿ≤ÿ©', 'ÿµÿ≠ÿ™Ÿä', 'ÿ∑ÿ®Ÿä', 'ŸÖÿ≥ÿ™ÿ¥ŸÅŸâ'])
        
        if has_academic and not has_medical:
            d['label'] = 'Academic Cheating'
            d['fixed_by'] = 'comprehensive_fix_cross_category'
            fixes['cross_category_fixed'] += 1

print(f'   Fixed: {fixes["cross_category_fixed"]}')

# ========== 5. FIX QUESTIONS IN VIOLATIONS ==========
print('\n‚ùì 5. Fixing Questions in Violations...')
question_patterns = ['ŸÖŸäŸÜ Ÿäÿπÿ±ŸÅ', 'ÿßÿ®Ÿä ÿßÿ≠ÿØ', 'ŸÉŸäŸÅ ÿßŸÇÿØÿ±', 'ŸàŸäŸÜ ÿßÿ≠ÿµŸÑ', 'ŸÖŸÖŸÉŸÜ ÿßÿ≠ÿØ Ÿäÿ≥ÿßÿπÿØ', 'ÿßÿ≠ÿ™ÿßÿ¨ ŸÖÿ≥ÿßÿπÿØÿ©']

for d in data:
    label = d.get('label', '')
    if label in ['Normal', 'Unethical', 'Hacking']:
        continue  # Skip Normal and keyword-based categories
    
    txt = d.get('text', '').lower()
    
    # Check if it looks like a question
    is_question = any(q in txt for q in question_patterns)
    
    # Check if it's NOT a disguised service
    is_service = any(s in txt for s in ['ŸÑŸÑÿ™ŸàÿßÿµŸÑ', 'ŸÖÿ™ŸàŸÅÿ±', 'ŸäŸàÿ¨ÿØ ŸÑÿØŸäŸÜÿß', 'ÿ™ŸàÿßÿµŸÑ ŸÖÿπŸä', 'ÿÆÿßÿµ'])
    
    if is_question and not is_service:
        d['label'] = 'Normal'
        d['fixed_by'] = 'comprehensive_fix_question'
        fixes['questions_fixed'] += 1

print(f'   Fixed: {fixes["questions_fixed"]}')

# ========== SAVE ==========
print('\n' + '=' * 70)
with open(file_path, 'w') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

total_fixes = sum(fixes.values())
print(f'‚úÖ COMPREHENSIVE FIX COMPLETE')
print(f'   Original Samples: {original_count}')
print(f'   Final Samples: {len(data)}')
print(f'   Total Fixes: {total_fixes}')
print('')
for key, count in fixes.items():
    if count > 0:
        print(f'   - {key}: {count}')

# Show new distribution
print('\nüìä New Distribution:')
labels = Counter(d['label'] for d in data)
for lbl, cnt in labels.most_common():
    print(f'   {lbl}: {cnt}')

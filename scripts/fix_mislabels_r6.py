"""
Fix Mislabeled Training Samples - Round 6 (Sixth Full Re-audit)
Final cleanup: religious content, bus numbers, GPA discussions, and cross-category fixes.
"""
import json
import os
import shutil
from datetime import datetime
from collections import Counter

DATA_PATH = "al_rased/data/labeledSamples/training_data.json"
BACKUP_DIR = "al_rased/data/labeledSamples/backups"

FIXES = [
    # ========================================================
    # MEDICAL FRAUD â†’ NORMAL (not medical at all)
    # ========================================================
    (1476, "Ø·Ø¨ÙŠØ¹ÙŠ", ["Ø·Ø¨ÙŠØ¹ÙŠ"],
     "Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§ØµØ§Øª Ù†Ù‚Ù„ Ù…ÙˆØ³Ù…ÙŠ = Ù„ÙŠØ³Øª Ø§Ø­ØªÙŠØ§Ù„ Ø·Ø¨ÙŠ Ø¨Ù„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ù‚Ù„"),
    (1483, "Ø·Ø¨ÙŠØ¹ÙŠ", ["Ø·Ø¨ÙŠØ¹ÙŠ"],
     "Ù„Ùˆ Ø·Ù„Ø¹ Ø¨Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ 4.66 Ù„Ù…Ø§ ÙŠÙ†Ø²Ù„ Ø¨Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ§ ÙŠØµÙŠØ± 4.64 = Ù†Ù‚Ø§Ø´ Ù…Ø¹Ø¯Ù„ GPA"),

    # ========================================================
    # HACKING â†’ UNETHICAL (child exploitation content)
    # ========================================================
    (1484, "ØºÙŠØ± Ø£Ø®Ù„Ø§Ù‚ÙŠ (Ø¹Ø±Ø¶)", ["ØºÙŠØ± Ø£Ø®Ù„Ø§Ù‚ÙŠ (Ø¹Ø±Ø¶)"],
     "Ø£ÙÙ„Ø§Ù… Ø£Ø·ÙØ§Ù„ ÙˆØ§ØºØªØµØ§Ø¨ ÙˆØªØ¬Ø³Ø³ = Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø£Ø®Ù„Ø§Ù‚ÙŠ Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ ÙˆÙ„ÙŠØ³ ØªÙ‡ÙƒÙŠØ±"),

    # ========================================================
    # UNETHICAL â†’ NORMAL (prayer/Ø¯Ø¹Ø§Ø¡)
    # ========================================================
    (1490, "Ø·Ø¨ÙŠØ¹ÙŠ", ["Ø·Ø¨ÙŠØ¹ÙŠ"],
     "Ø£Ø³Ø£Ù„ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ¹Ø¬Ø²Ù‡ Ø´ÙŠØ¡ Ø£Ù† ÙŠØ¹Ø·ÙŠÙƒ = Ø¯Ø¹Ø§Ø¡ Ø¯ÙŠÙ†ÙŠ Ø¨Ø±ÙŠØ¡"),

    # ========================================================
    # UNETHICAL â†’ SPAM (comedy group promotion)
    # ========================================================
    (1491, "Ø³Ø¨Ø§Ù…", ["Ø³Ø¨Ø§Ù…"],
     "Ø¶Ø§ÙŠØ¬ ÙˆØªØ±ÙŠØ¯ ØªØ¶Ø­Ùƒ ØªØ¹Ø§Ù„ Ù„Ø±Ø¨Ø¹ Ø§Ù„Ù„Ù‡ ØªØ­Ø´ÙŠØ´ = ØªØ±ÙˆÙŠØ¬ Ù‚Ø±ÙˆØ¨ ØªÙ„ÙŠØ¬Ø±Ø§Ù…"),

    # ========================================================
    # UNETHICAL â†’ FINANCIAL SCAM (work from home scam)
    # ========================================================
    (1498, "Ø§Ø­ØªÙŠØ§Ù„ Ù…Ø§Ù„ÙŠ (Ø¹Ø±Ø¶)", ["Ø§Ø­ØªÙŠØ§Ù„ Ù…Ø§Ù„ÙŠ (Ø¹Ø±Ø¶)"],
     "Ù…Ø¬Ø§Ù„ Ù…Ø±Ù‡ Ø­Ù„Ùˆ ØªØ§Ø®Ø° ÙÙ„ÙˆØ³ ÙˆØ§Ù†Øª Ù‚Ø§Ø¹Ø¯ ÙÙŠ Ø§Ù„Ù…Ù†Ø²Ù„ = Ø§Ø­ØªÙŠØ§Ù„ Ù…Ø§Ù„ÙŠ"),

    # ========================================================
    # SPAM â†’ NORMAL (educational/religious content)
    # ========================================================
    (2022, "Ø·Ø¨ÙŠØ¹ÙŠ", ["Ø·Ø¨ÙŠØ¹ÙŠ"],
     "Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù…Ù†ØµØ© Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ù„Ø¨Ù„Ø§ØºØ§Øª = Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø±Ø´Ø§Ø¯ÙŠØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ©"),
    (2045, "Ø·Ø¨ÙŠØ¹ÙŠ", ["Ø·Ø¨ÙŠØ¹ÙŠ"],
     "ÙŠØ§ Ù…Ù†Ø²Ù„ Ø§Ù„Ø¢ÙŠØ§Øª ÙˆØ§Ù„ÙØ±Ù‚Ø§Ù† Ø¨ÙŠÙ†ÙŠ ÙˆØ¨ÙŠÙ†Ùƒ Ø­Ø±Ù…Ø© Ø§Ù„Ù‚Ø±Ø¢Ù† = Ø´Ø¹Ø± Ø¯ÙŠÙ†ÙŠ"),

    # ========================================================
    # FINANCIAL SCAMS â†’ NORMAL (religious/general content)
    # ========================================================
    (2027, "Ø·Ø¨ÙŠØ¹ÙŠ", ["Ø·Ø¨ÙŠØ¹ÙŠ"],
     "Ù‚Ù†Ø§Ø¹Ø§Øª Ø±Ù…Ø¶Ø§Ù†ÙŠØ© Ø¹Ù† Ø§Ù„Ø·Ø§Ø¹Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø§ØµÙŠ = Ù…Ø­ØªÙˆÙ‰ Ø¯ÙŠÙ†ÙŠ"),

    # ========================================================
    # UNETHICAL â†’ SPAM (Minecraft server)
    # ========================================================
    (2037, "Ø³Ø¨Ø§Ù…", ["Ø³Ø¨Ø§Ù…"],
     "ØªÙ… Ø§ÙØªØªØ§Ø­ Ø³ÙŠØ±ÙØ± Special Craft ØªÙŠÙ…Ø§Øª ÙˆÙØ¹Ø§Ù„ÙŠØ§Øª = Ø¥Ø¹Ù„Ø§Ù† Ø³ÙŠØ±ÙØ± Ù„Ø¹Ø¨Ø©"),

    # ========================================================
    # FINANCIAL SCAMS â†’ SPAM (business consultancy)
    # ========================================================
    (2041, "Ø³Ø¨Ø§Ù…", ["Ø³Ø¨Ø§Ù…"],
     "Ø¯Ø±Ø§Ø³Ø© Ù…Ø´Ø±ÙˆØ¹Ùƒ Ø¹Ù„ÙŠÙ†Ø§ Ø¯Ø±Ø§Ø³Ø© Ø¬Ø¯ÙˆÙ‰ = Ø®Ø¯Ù…Ø§Øª Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø£Ø¹Ù…Ø§Ù„"),
]


def main():
    print("=" * 60)
    print("ðŸ”§ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª - Ø§Ù„Ø¬ÙˆÙ„Ø© Ø§Ù„Ø³Ø§Ø¯Ø³Ø©")
    print("=" * 60)

    with open(DATA_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(f"ðŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª: {len(data)}")

    os.makedirs(BACKUP_DIR, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = os.path.join(BACKUP_DIR, f"training_data_pre_fix_r6_{ts}.json")
    shutil.copy2(DATA_PATH, backup_path)
    print(f"ðŸ’¾ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")

    print("\nðŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø¨Ù„:")
    before = Counter(d["label"] for d in data)
    for k, v in before.most_common():
        print(f"  {k}: {v}")

    print(f"\nðŸ”§ ØªØ·Ø¨ÙŠÙ‚ {len(FIXES)} Ø¥ØµÙ„Ø§Ø­...")
    print("-" * 60)

    fix_count = 0
    skipped = 0
    for idx, new_label, new_labels, reason in FIXES:
        if idx >= len(data):
            continue
        sample = data[idx]
        old_label = sample.get("label", "")
        if old_label == new_label and sample.get("labels", []) == new_labels:
            skipped += 1
            continue

        sample["label"] = new_label
        sample["labels"] = new_labels
        sample["note"] = f"Fix R6: {old_label} -> {new_label} ({reason})"
        sample["reviewed_at"] = datetime.now().isoformat()
        sample["reviewed_by"] = "full_audit_r6_feb2026"

        fix_count += 1
        text_preview = sample["text"][:50].replace('\n', ' ')
        print(f"  âœ… [{idx}] {old_label} -> {new_label}")
        print(f"       {text_preview}...")

    if skipped:
        print(f"\n  â­ï¸  ØªØ®Ø·ÙŠ {skipped}")

    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\nðŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¨Ø¹Ø¯:")
    after = Counter(d["label"] for d in data)
    for k, v in after.most_common():
        diff = v - before.get(k, 0)
        marker = f" ({'+' if diff > 0 else ''}{diff})" if diff != 0 else ""
        print(f"  {k}: {v}{marker}")

    print(f"\nâœ… ØªÙ… Ø¥ØµÙ„Ø§Ø­ {fix_count} Ø¹ÙŠÙ†Ø©")


if __name__ == "__main__":
    main()

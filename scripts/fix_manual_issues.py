#!/usr/bin/env python3
"""
FIX MANUAL REVIEW ISSUES
Based on manual verification findings:
1. Hacking: Remove gaming servers, password questions, student jokes
2. Unethical: Remove normal questions, spam
3. Normal: Move hidden services to correct categories
"""
import json
from collections import Counter

print('ğŸ”§ FIXING MANUAL REVIEW ISSUES')
print('=' * 70)

file_path = 'al_rased/data/labeledSamples/training_data.json'
with open(file_path, 'r') as f:
    data = json.load(f)

fixes = {
    'hacking_to_normal': 0,
    'hacking_to_spam': 0,
    'unethical_to_normal': 0,
    'unethical_to_spam': 0,
    'normal_to_medical': 0,
    'normal_to_academic': 0,
}

# ========== 1. FIX HACKING ==========
print('\nğŸ”“ 1. Fixing Hacking Category...')

# Patterns that are NOT hacking
gaming_patterns = ['Ø³ÙŠØ±ÙØ±', 'ÙƒØ±Ø§ÙØª', 'minecraft', 'Ù…Ø§ÙŠÙ†', 'ØªÙŠÙ…Ø§Øª', 'ÙÙƒØ±Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±']
spam_patterns = ['Ù…ØªÙˆÙØ± ØªÙˆØ«ÙŠÙ‚', 'Ù…ØªÙˆÙØ± ÙŠÙˆØ²Ø±Ø§Øª', 'Ø±ØµÙŠØ¯ Ù†ÙˆÙ†', 'Ù‚Ø³Ø§ÙŠÙ…', 'Ø´Ø­Ù†']
question_patterns = ['ÙƒÙŠÙ', 'Ø§Ø±ÙŠØ¯ Ø´Ø±Ø­', 'Ù…Ù…ÙƒÙ†', 'Ø§Ù†Ø³Ø­Ø¨Øª', 'ÙˆØ±Ø¬Ø¹Øª', 'Ù…Ø§ Ø¨ØºÙŠØ±', 'ØªØªÙ‡ÙƒØ± Ø¯Ø±Ø¬Ø§ØªÙŠ']
true_hacking = ['ØªÙ‡ÙƒÙŠØ±', 'Ø§Ø®ØªØ±Ø§Ù‚', 'Ù‡ÙƒØ±', 'Ø³Ø±Ù‚Ø© Ø­Ø³Ø§Ø¨', 'Ø³Ø­Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'ÙÙƒ Ø­Ù…Ø§ÙŠØ©', 'ØªØ¬Ø³Ø³']

for d in data:
    if d.get('label') != 'Hacking':
        continue
    
    txt = d.get('text', '').lower()
    
    # Check if it's a gaming server -> Spam
    if any(p in txt for p in gaming_patterns):
        if not any(h in txt for h in true_hacking):
            d['label'] = 'Spam'
            d['fixed_by'] = 'manual_review_fix'
            fixes['hacking_to_spam'] += 1
            continue
    
    # Check if it's spam (not hacking service)
    if any(p in txt for p in spam_patterns):
        if not any(h in txt for h in true_hacking):
            d['label'] = 'Spam'
            d['fixed_by'] = 'manual_review_fix'
            fixes['hacking_to_spam'] += 1
            continue
    
    # Check if it's a question -> Normal
    if any(p in txt for p in question_patterns):
        if not any(h in txt for h in true_hacking):
            d['label'] = 'Normal'
            d['fixed_by'] = 'manual_review_fix'
            fixes['hacking_to_normal'] += 1
            continue

print(f'   Hacking -> Normal: {fixes["hacking_to_normal"]}')
print(f'   Hacking -> Spam: {fixes["hacking_to_spam"]}')

# ========== 2. FIX UNETHICAL ==========
print('\nğŸ” 2. Fixing Unethical Category...')

# Patterns that are NOT unethical
normal_questions = ['Ù…ÙŠÙ† ØªØ®ØµØµÙ‡', 'Ø§Ø±ÙŠØ¯', 'Ø§Ø¨ÙŠ', 'ÙƒÙ… Ø³Ø¹Ø±', 'Ø´Ù„ÙˆÙ†', 'ÙƒÙŠÙ']
spam_in_unethical = ['Ø¨ÙŠØ¹ Ù…Ø¹Ø±ÙØ§Øª', 'Ø±ÙØ¹ Ù…Ù†ØµØ§Øª', 'ØªÙØ¹ÙŠÙ„ Ù…Ù…ÙŠØ²', 'ÙŠÙˆØ²Ø±Ø§Øª']
true_unethical = ['Ø³ÙƒØ³', 'porn', 'xxx', 'Ù†ÙŠÙƒ', 'Ù‡ÙŠØ¬Ø§Ù†Ù‡', 'Ù†ÙˆØ¯Ø²', 'ØªØ­Ø±Ø´', 'Ø§Ø·ÙØ§Ù„', 'Ø­Ø´ÙŠØ´', 'Ù…Ø®Ø¯Ø±Ø§Øª']

for d in data:
    if d.get('label') != 'Unethical':
        continue
    
    txt = d.get('text', '').lower()
    
    # Skip if it has true unethical content
    if any(u in txt for u in true_unethical):
        continue
    
    # Check if it's spam
    if any(p in txt for p in spam_in_unethical):
        d['label'] = 'Spam'
        d['fixed_by'] = 'manual_review_fix'
        fixes['unethical_to_spam'] += 1
        continue
    
    # Check if it's a normal question
    if any(p in txt for p in normal_questions) and len(txt) < 200:
        d['label'] = 'Normal'
        d['fixed_by'] = 'manual_review_fix'
        fixes['unethical_to_normal'] += 1
        continue
    
    # If it doesn't have true unethical keywords, move to Normal
    if not any(u in txt for u in true_unethical):
        d['label'] = 'Normal'
        d['fixed_by'] = 'manual_review_fix'
        fixes['unethical_to_normal'] += 1

print(f'   Unethical -> Normal: {fixes["unethical_to_normal"]}')
print(f'   Unethical -> Spam: {fixes["unethical_to_spam"]}')

# ========== 3. FIX NORMAL (Hidden Services) ==========
print('\nğŸŸ¢ 3. Fixing Normal (Hidden Services)...')

# Services that should NOT be in Normal
medical_services = ['Ø³ÙƒÙ„ÙŠÙ', 'Ø§Ø¬Ø§Ø²Ø© Ù…Ø±Ø¶ÙŠØ©', 'Ø¹Ø°Ø± Ø·Ø¨ÙŠ', 'ØªÙ‚Ø±ÙŠØ± Ù…Ø±Ø¶ÙŠ']
academic_services = ['Ø­Ù„ ÙˆØ§Ø¬Ø¨Ø§Øª', 'Ù†Ø­Ù„ ÙˆØ§Ø¬Ø¨Ø§Øª', 'Ø­Ù„ Ù…Ø´Ø§Ø±ÙŠØ¹', 'ÙƒØªØ§Ø¨Ø© Ø¨Ø­ÙˆØ«']

# Words that indicate it's just a question/request (keep in Normal)
question_words = ['Ø§Ø¨ÙŠ', 'Ø§Ø¨ØºÙ‰', 'Ø§Ø±ÙŠØ¯', 'Ù…ÙŠÙ† ÙŠØ¹Ø±Ù', 'Ù…Ø­ØªØ§Ø¬']

for d in data:
    if d.get('label') != 'Normal':
        continue
    
    txt = d.get('text', '').lower()
    
    # Check if it's an ACTIVE service (not a request)
    is_question = any(q in txt for q in question_words)
    is_service = any(s in txt for s in ['Ù…ØªÙˆÙØ±', 'Ø´ØºØ§Ù„ Ø§Ù„Ø§Ù†', 'Ø§Ù„ØªØ¹Ø§Ø¨ Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†Ø¬Ø§Ø²', 'ØªØ­ÙˆÙŠÙ„ Ø¨Ø¹Ø¯'])
    
    if is_service and not is_question:
        # Medical service
        if any(m in txt for m in medical_services):
            d['label'] = 'Medical Fraud'
            d['fixed_by'] = 'manual_review_fix'
            fixes['normal_to_medical'] += 1
            continue
        
        # Academic service
        if any(a in txt for a in academic_services):
            d['label'] = 'Academic Cheating'
            d['fixed_by'] = 'manual_review_fix'
            fixes['normal_to_academic'] += 1
            continue

print(f'   Normal -> Medical Fraud: {fixes["normal_to_medical"]}')
print(f'   Normal -> Academic Cheating: {fixes["normal_to_academic"]}')

# ========== SAVE ==========
with open(file_path, 'w') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

# ========== SUMMARY ==========
print('\n' + '=' * 70)
total = sum(fixes.values())
print(f'âœ… TOTAL FIXES: {total}')

# Show new distribution
labels = Counter(d['label'] for d in data)
print('\nğŸ“Š Updated Distribution:')
for lbl, cnt in labels.most_common():
    print(f'   {lbl}: {cnt}')

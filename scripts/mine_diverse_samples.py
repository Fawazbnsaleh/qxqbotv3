#!/usr/bin/env python3
"""
Mine MORE DIVERSE samples for Unethical and Hacking categories
Focus on different patterns and phrasings to improve model recall
"""
import json
import os
import glob
import random

print('ğŸ” Mining Diverse Samples for Weak Categories')
print('=' * 70)

# ========== EXPANDED KEYWORD PATTERNS ==========

# Unethical - Multiple phrasings of same concepts
unethical_patterns = [
    # Sexual content - various phrasings
    'Ø³ÙƒØ³', 'Ù†ÙŠÙƒ', 'Ø¨ÙˆØ±Ù†', 'porn', 'xxx', 'Ø§ÙÙ„Ø§Ù… Ù„Ù„ÙƒØ¨Ø§Ø±', 'Ù…Ø­ØªÙˆÙ‰ Ù„Ù„ÙƒØ¨Ø§Ø±', '+18',
    '18+', 'ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø³Ø§Ø®Ù†Ø©', 'Ù…Ù‚Ø§Ø·Ø¹ Ø®Ø§ØµØ©', 'Ø¨Ø¯ÙˆÙ† Ù…Ù„Ø§Ø¨Ø³', 'Ø¹Ø§Ø±ÙŠ', 'nude',
    'onlyfans', 'ÙÙ‚Ø· Ù„Ù„ÙƒØ¨Ø§Ø±', 'Ù‡ÙŠØ¬Ø§Ù†Ù‡', 'Ù†ÙˆØ¯Ø²', 'ÙÙŠØ¯ÙŠÙˆ ÙƒÙˆÙ„', 'Ø³ÙƒØ³ Ø´Ø§Øª',
    # Child exploitation
    'Ø§Ø·ÙØ§Ù„', 'Ù‚Ø§ØµØ±', 'ØµØºÙŠØ±', 'ØªØ­Ø±Ø´',
    # LGBT content (may be considered unethical in some contexts)
    'Ø´ÙŠÙ…ÙŠÙ„', 'Ø³Ø­Ø§Ù‚', 'Ù„ÙˆØ§Ø·', 'Ø´ÙˆØ§Ø°', 'Ù…Ø«Ù„ÙŠ',
    # Violence
    'Ø°Ø¨Ø­', 'ØªØ¹Ø°ÙŠØ¨', 'Ù‚ØªÙ„', 'Ø¯Ù…', 'Ø¬Ø«Ø«',
    # Drugs - expanded
    'Ø­Ø´ÙŠØ´', 'Ù…Ø®Ø¯Ø±Ø§Øª', 'ÙƒÙˆÙƒØ§ÙŠÙŠÙ†', 'Ù‡ÙŠØ±ÙˆÙŠÙ†', 'Ø´Ø¨Ùˆ', 'ÙƒØ±ÙŠØ³ØªØ§Ù„', 'ÙƒØ¨ØªØ§Ø¬ÙˆÙ†',
    'ØªØ±Ø§Ù…Ø§Ø¯ÙˆÙ„', 'Ø­Ø¨ÙˆØ¨', 'Ù…Ù†Ø´Ø·Ø§Øª', 'Ù…Ù‡Ù„ÙˆØ³Ø§Øª',
    # Weapons
    'Ø§Ø³Ù„Ø­Ø©', 'Ù…Ø³Ø¯Ø³', 'Ø±Ø´Ø§Ø´', 'Ø¨Ù†Ø¯Ù‚ÙŠØ©', 'Ø³Ù„Ø§Ø­', 'Ø°Ø®ÙŠØ±Ø©',
    # Spy/Surveillance services
    'ØªØ¬Ø³Ø³', 'Ù…Ø±Ø§Ù‚Ø¨Ø©', 'ØªØµÙˆÙŠØ± Ø®ÙÙŠ', 'ÙƒØ§Ù…ÙŠØ±Ø§Øª Ø³Ø±ÙŠØ©',
    # Telegram bot links for adult content
    't.me/', 'bot?start=',
]

# Hacking - Various service patterns
hacking_patterns = [
    # Hacking services
    'ØªÙ‡ÙƒÙŠØ±', 'Ù‡ÙƒØ±', 'Ø§Ø®ØªØ±Ø§Ù‚', 'Ø³Ø±Ù‚Ø© Ø­Ø³Ø§Ø¨', 'ÙÙƒ Ø­Ù…Ø§ÙŠØ©', 'ØªØ¬Ø§ÙˆØ²',
    # Account manipulation
    'Ø­Ø¸Ø± Ø­Ø³Ø§Ø¨', 'ÙØªØ­ Ø­Ø³Ø§Ø¨ Ù…Ø­Ø¸ÙˆØ±', 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø­Ø³Ø§Ø¨', 'Ø³Ø­Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª',
    # Platform-specific hacking
    'ØªÙ‡ÙƒÙŠØ± ÙˆØ§ØªØ³Ø§Ø¨', 'ØªÙ‡ÙƒÙŠØ± Ø§Ù†Ø³ØªÙ‚Ø±Ø§Ù…', 'ØªÙ‡ÙƒÙŠØ± ØªÙŠÙƒ ØªÙˆÙƒ', 'ØªÙ‡ÙƒÙŠØ± Ø³Ù†Ø§Ø¨',
    'ØªÙ‡ÙƒÙŠØ± ÙÙŠØ³Ø¨ÙˆÙƒ', 'ØªÙ‡ÙƒÙŠØ± ØªÙˆÙŠØªØ±', 'ØªÙ‡ÙƒÙŠØ± ØªÙ„Ø¬Ø±Ø§Ù…',
    # Phone hacking
    'ØªÙ‡ÙƒÙŠØ± Ø¬ÙˆØ§Ù„', 'ØªÙ‡ÙƒÙŠØ± Ù‡Ø§ØªÙ', 'Ø§Ø®ØªØ±Ø§Ù‚ Ù‡Ø§ØªÙ', 'ÙØ±Ù…ØªØ© Ø¹Ù† Ø¨Ø¹Ø¯',
    # Cyber security services (malicious)
    'Ø§Ù…Ù† Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ', 'ÙØ±ÙŠÙ‚ Ù‡ÙƒØ±Ø²', 'Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù‡ÙƒØ±',
    # Tools
    'Ù„ÙˆØ¯Ø±', 'ØºØ´', 'Ø´ÙŠØª', 'cheat', 'hack',
    # Fake followers/likes (borderline)
    'Ø±Ø´Ù‚ Ù…ØªØ§Ø¨Ø¹ÙŠÙ†', 'ØµÙŠØ¯ Ø­Ø³Ø§Ø¨Ø§Øª', 'ÙŠÙˆØ²Ø±Ø§Øª',
]

# ========== MINING ==========

group_messages_path = 'al_rased/data/group_messages'
mined_unethical = []
mined_hacking = []

if os.path.exists(group_messages_path):
    json_files = glob.glob(f'{group_messages_path}/*.json')
    print(f'Scanning {len(json_files)} group message files...')
    
    for json_file in json_files:
        try:
            with open(json_file, 'r') as f:
                messages = json.load(f)
            
            for msg in messages:
                if not isinstance(msg, dict):
                    continue
                    
                txt = msg.get('text', '').lower()
                full_text = msg.get('text', '')
                
                if len(full_text) < 30:
                    continue
                
                # Check Unethical
                matched_unethical = [k for k in unethical_patterns if k in txt]
                if matched_unethical:
                    # Stronger signal: multiple keywords or explicit content
                    if len(matched_unethical) >= 2 or any(k in txt for k in ['Ø³ÙƒØ³', 'porn', 'xxx', 'Ù†ÙŠÙƒ', 'Ù‡ÙŠØ¬Ø§Ù†Ù‡']):
                        mined_unethical.append({
                            'text': full_text,
                            'label': 'Unethical',
                            'matched': matched_unethical[:3]
                        })
                
                # Check Hacking
                matched_hacking = [k for k in hacking_patterns if k in txt]
                if matched_hacking:
                    # Must have hacking intent, not just asking
                    is_question = any(q in txt for q in ['ÙƒÙŠÙ', 'Ù…ÙŠÙ† ÙŠØ¹Ø±Ù', 'Ø§Ø¨ÙŠ', 'Ø§Ø­ØªØ§Ø¬'])
                    is_service = any(s in txt for s in ['Ù…ØªÙˆÙØ±', 'Ù„Ù„ØªÙˆØ§ØµÙ„', 'ÙŠÙˆØ¬Ø¯ Ù„Ø¯ÙŠÙ†Ø§', 'Ø®Ø§Øµ', 'dm'])
                    
                    if is_service and not is_question:
                        mined_hacking.append({
                            'text': full_text,
                            'label': 'Hacking',
                            'matched': matched_hacking[:3]
                        })
        except:
            continue

# Deduplicate
unique_unethical = list({s['text']: s for s in mined_unethical}.values())
unique_hacking = list({s['text']: s for s in mined_hacking}.values())

print(f'\nğŸ“Š Mining Results:')
print(f'   Unethical: {len(unique_unethical)} unique samples')
print(f'   Hacking: {len(unique_hacking)} unique samples')

# Load current data
file_path = 'al_rased/data/labeledSamples/training_data.json'
with open(file_path, 'r') as f:
    data = json.load(f)

existing_texts = {d['text'] for d in data}

# Add new unique samples
added_unethical = 0
added_hacking = 0

for s in unique_unethical[:100]:
    if s['text'] not in existing_texts:
        data.append({
            'text': s['text'],
            'label': 'Unethical',
            'source': 'diverse_mining'
        })
        existing_texts.add(s['text'])
        added_unethical += 1

for s in unique_hacking[:100]:
    if s['text'] not in existing_texts:
        data.append({
            'text': s['text'],
            'label': 'Hacking',
            'source': 'diverse_mining'
        })
        existing_texts.add(s['text'])
        added_hacking += 1

with open(file_path, 'w') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

print(f'\nâœ… Added to training data:')
print(f'   Unethical: +{added_unethical} new samples')
print(f'   Hacking: +{added_hacking} new samples')

# Show new distribution
from collections import Counter
labels = Counter(d['label'] for d in data)
print(f'\nğŸ“ˆ Updated Distribution:')
for lbl, cnt in labels.most_common():
    print(f'   {lbl}: {cnt}')


import json
import re
import os
import sys
from datetime import datetime

# Add parent path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Expert Rules (Regex Patterns) - Expanded with typos and obfuscations
EXPERT_RULES = {
    'Academic Cheating': [
        r'Ø­Ù„\s*ÙˆØ§Ø¬Ø¨', r'Ø­Ù„\s*Ø§Ø®ØªØ¨Ø§Ø±', r'Ù…Ø´Ø§Ø±ÙŠØ¹\s*ØªØ®Ø±Ø¬', r'Ø±Ø³Ø§Ø¦?Ù„\s*Ù…Ø§Ø¬Ø³ØªÙŠØ±', 
        r'Ø§Ø¹Ø¯Ø§Ø¯\s*Ø¨Ø­ÙˆØ«', r'Ø®Ø¯Ù…Ø§Øª\s*Ø·Ù„Ø§Ø¨ÙŠØ©', r'Ø§Ø³Ø§ÙŠÙ…Ù†Øª', r'ÙƒÙˆÙŠØ²Ø§Øª', r'ØªØ³Ù…ÙŠØ¹',
        r'Ø­Ù„ÙˆÙ„\s*ÙˆØ§Ø¬Ø¨Ø§Øª', r'Ù…Ø³Ø§Ø¹Ø¯Ø©\s*ÙÙŠ\s*Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±', r'Ù‚Ø±ÙˆØ¨\s*Ø­Ù„', r'Ø£Ø¨Ø­Ø§Ø«\s*Ø¬Ø§Ù…Ø¹ÙŠØ©',
        r'Ø§Ù…ØªØ­Ø§Ù†Øª', r'Ø§Ø³Ø§ÙŠÙ†Ù…Ù†Øª', r'Ø¨Ø±ÙˆØ¬ÙƒØª', r'ØªÙ„Ù‚Ø±Ø§Ù…', r'Ù‚Ø±ÙˆØ¨Ø§Øª\s*Ø¬Ø§Ù…Ø¹ÙŠØ©'
    ],
    'Medical Fraud': [
        r'Ø³ÙƒÙ„ÙŠÙ', r'Ø§Ø¬Ø§Ø²Ø©\s*Ù…Ø±Ø¶ÙŠØ©', r'ØªÙ‚Ø±ÙŠØ±\s*Ø·Ø¨ÙŠ', r'Ø¹Ø°Ø±\s*Ø·Ø¨ÙŠ', r'Ù…Ø´Ù‡Ø¯\s*Ù…Ø±Ø§ÙÙ‚Ø©',
        r'Ù…Ø³ØªØ´ÙÙ‰\s*Ø­ÙƒÙˆÙ…ÙŠ', r'Ù…Ù†ØµØ©\s*ØµØ­ØªÙŠ', r'ØªØ·Ø¨ÙŠÙ‚\s*ØµØ­ØªÙŠ', r'Ù…Ø±Ø¶ÙŠÙ‡\s*Ù…Ø¹ØªÙ…Ø¯Ù‡',
        r'Ø§Ø¬Ø§Ø²Ù‡\s*Ù…Ø±Ø¶ÙŠÙ‡', r'Ø³Ùƒ\s*Ù„ÙŠÙ'
    ],
    'Financial Scams': [
        r'Ø§Ø³ØªØ«Ù…[Ø±Ø§Ø±]', r'Ø§Ø±Ø¨Ø§Ø­\s*Ù…Ø¶Ù…ÙˆÙ†Ø©', r'ØªØ¯Ø§ÙˆÙ„', r'ÙÙˆØ±ÙƒØ³', r'Ø¹Ù…Ù„Ø§Øª\s*Ø±Ù‚Ù…ÙŠØ©',
        r'Ø§Ø¯Ø§Ø±Ø©\s*Ù…Ø­Ø§ÙØ¸', r'Ø±Ø¨Ø­\s*ÙŠÙˆÙ…ÙŠ', r'Ø¯Ø®Ù„\s*Ø§Ø¶Ø§ÙÙŠ', r'ØªÙˆØµÙŠØ§Øª\s*Ø°Ù‡Ø¨',
        r'crypto', r'bitcoin', r'usdt', r'binance', r'investment', r'profit',
        r'Ø¨ÙŠØªÙƒÙˆÙŠÙ†', r'Ø§ÙŠØ«ÙŠØ±ÙŠÙˆÙ…', r'Ø¹Ù…Ù„Ø§Øª', r'Ø§Ø³Ù‡Ù…'
    ],
    'Hacking': [
        r'ØªÙ‡ÙƒÙŠØ±', r'Ø§Ø®ØªØ±Ø§Ù‚', r'ØªØ¬Ø³Ø³', r'Ø³Ø­Ø¨\s*ØµÙˆØ±', r'Ø§Ø³ØªØ±Ø¯Ø§Ø¯\s*Ø­Ø³Ø§Ø¨',
        r'Ø²ÙŠØ§Ø¯Ø©\s*Ù…ØªØ§Ø¨Ø¹ÙŠÙ†', r'ØªÙˆØ«ÙŠÙ‚\s*Ø­Ø³Ø§Ø¨', r'Ø±Ø´Ù‚', r'Ù…ØªØ§Ø¨Ø¹ÙŠÙ†',
        r'Ø§Ø±Ù‚Ø§Ù…\s*ÙˆÙ‡Ù…ÙŠØ©' # Moved from Spam
    ],
    'Unethical': [
        r'Ø³ÙƒØ³', r'Ù†ÙŠ[ÙƒÚª]', r'Ù…Ù…Ø­ÙˆÙ†', r'Ø¯ÙŠÙˆØ«', r'Ù‚Ø­Ø¨Ø©', r'Ø³Ù‡Ø±Ø§Øª', r'Ù…Ø³Ø§Ø¬', r'Ù…Ø¯Ù„Ø¹Ø©',
        r'Ø­Ø´ÙŠØ´', r'Ù…Ø®Ø¯Ø±Ø§Øª', r'ÙƒØ¨ØªØ§Ø¬ÙˆÙ†', r'Ø´Ø¨Ùˆ', r'Ù†ÙˆØ¯Ø²', r'Ø§ÙÙ„Ø§Ù…\s*Ø§Ø¨Ø§Ø­ÙŠØ©', r'Ø²Ù†Ø§'
    ],
    # Spam is usually a fallback if others don't match but contains generic ad keywords
    'Spam': [
        r'Ø³ÙŠØ±ÙØ±\s*Ù…Ø§ÙŠÙ†ÙƒØ±Ø§ÙØª', r'ØªØ¨Ø§Ø¯Ù„\s*Ù†Ø´Ø±', r'Ø§Ø´ØªØ±Ùƒ\s*ÙÙŠ\s*Ù‚Ù†Ø§ØªÙ†Ø§', 
        r'ØªÙØ¹ÙŠÙ„\s*ØªÙ„ÙŠØ¬Ø±Ø§Ù…'
    ]
}

def clean_text(text):
    return text.lower()

def check_expert_rules(text):
    text = clean_text(text)
    matches = []
    for label, patterns in EXPERT_RULES.items():
        for pattern in patterns:
            if re.search(pattern, text):
                matches.append((label, pattern))
    return matches

def main():
    print("ðŸ¤– Starting Expert Data Quality Audit...")
    
    data_path = 'al_rased/data/labeledSamples/training_data.json'
    with open(data_path, 'r') as f:
        data = json.load(f)
    print(f"ðŸ“Š Analyzing {len(data)} samples...")

    corrected_count = 0
    verified_count = 0
    
    for sample in data:
        text = sample['text']
        original_label = sample.get('label', 'Normal')
        original_labels = sample.get('labels', [original_label])
        if isinstance(original_labels, str): original_labels = [original_labels]

        expert_matches = check_expert_rules(text)
        expert_labels = list(set([m[0] for m in expert_matches]))

        # 1. Correction Logic
        if expert_labels:
            # Check if any new labels need to be added
            new_labels = set(original_labels)
            labels_changed = False
            
            for expert_label in expert_labels:
                if expert_label not in new_labels:
                    # Strict Logic:
                    # - If Normal/Spam -> Violation: FORCE ADD
                    # - If Violation -> Different Violation: FORCE ADD (Multi-label)
                    
                    if 'Normal' in new_labels:
                        new_labels.remove('Normal') # Remove Normal if adding violation
                        labels_changed = True
                    if 'Spam' in new_labels and expert_label != 'Spam':
                        # Valid discussion: Keep Spam if it's spammy, but usually violation supersedes
                        # For now, let's keep Spam if meaningful, but usually not
                        if len(new_labels) == 1: # If only Spam
                             new_labels.remove('Spam')
                        labels_changed = True
                    
                    new_labels.add(expert_label)
                    labels_changed = True

            if labels_changed:
                sample['labels'] = list(new_labels)
                sample['label'] = sample['labels'][0] # Backward compat
                match_patterns = [m[1] for m in expert_matches]
                sample['note'] = f"Corrected by Gemini: Detected keywords {match_patterns}"
                sample['corrected_at'] = datetime.now().isoformat()
                corrected_count += 1
            else:
                 # Already has the labels, just verify
                 match_patterns = [m[1] for m in expert_matches]
                 if 'Verified' not in sample.get('note', ''):
                    sample['note'] = f"Verified: Contains {match_patterns}"
                    verified_count += 1
        
        # 2. Financial Scam Specific Check (ETH, Crypto) in Normal
        # Already covered by regex but double check English terms if needed
        if 'Normal' in original_labels:
            if re.search(r'\b(eth|btc|usdt|profit|invest)\b', text, re.I):
                sample['label'] = 'Financial Scams'
                sample['labels'] = ['Financial Scams']
                sample['note'] = "Corrected by Gemini: Detected English crypto terms"
                sample['corrected_at'] = datetime.now().isoformat()
                corrected_count += 1

    # Save
    with open(data_path, 'w') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Audit Complete.")
    print(f"ðŸ”§ Corrected: {corrected_count} samples")
    print(f"âœ… Verified: {verified_count} samples")

if __name__ == "__main__":
    main()
